---
title: "envClean"
author:
- Department for Environment and Water
- Nigel Willoughby
date: "`r format(Sys.time(), '%A, %d %B, %Y. %H:%M')`"
output: rmarkdown::html_vignette
bibliography: packages.bib
vignette: >
  %\VignetteIndexEntry{envClean}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}

  knitr::opts_chunk$set(
    collapse = TRUE
    , comment = "#>"
  )

```

```{r setup}

  library(envClean)
  library(envReport)
  library(envFunc) # needed for add_raster_cell
  library(sf)
  library(tibble)
  library(tmap)
  library(raster)

  tmap_mode("plot")

  flor_all <- tibble::as_tibble(flor_all)
  
  # What crs to use for maps?
  use_crs <- 3577 # actually an epsg code. see epsg.io
  
  aoi <- aoi %>%
    sf::st_transform(crs = use_crs)
  
```

## About the package

Cleaning large, unstructured, biological (or `env`ironmental) data sets is a challenging task. `envClean` provides a range of functions to assist.

The approach taken has evolved out of many years undertaking such cleaning tasks. It assumes the desired end result is a plausible list of taxa recorded at space and time locations for use in further analysis. This is _not the same_ as an authoritative checklist of taxa for any space and time locations.

While there are many implied and explicit decisions to make (e.g. there may be a lot of work to set up for new data sets), there is no manual input required once those decisions are made - these functions have the potential to provide an automated workflow from combined data through to analysis-ready data.

## Get `envClean`

`envClean` is not on CRAN.

Install the development version from GitHub

```r
remotes::install_github("acanthiza/envClean")
```

Load `envClean`

```r
library("envClean")
```
## Suggested workflow

After many, many iterations, the following workflow has been found to be ok. Only ok. There is no awesome when cleaning large, unstructured data.

### Import

Querying and uniting disparate data sources into a single data set is a challenge in its own right. See `envImport` for tools to assist there. Once you've imported and combined all your data, read on.

Here, we'll start with combined floristic data (called `flor_all`) from the mallee in South Australia. This data set is provided with `envClean`.

```{r flor_all}

  flor_all

```

### Note on coordinate reference systems

There are two (possibly three) main coordinate reference systems (crs):

1. the crs for the original records. Often decimal degrees. Almost certainly using [epsg](https://epsg.io/) = [4283](https://epsg.io/4283) with these data will return the correct crs.
2. the crs to use for most spatial data. Set here (in setup chunk) to `use_crs` = `r use_crs`. It is likely that a projected crs will work best, particularly for buffering, filtering etc.
3. the crs for any other imported spatial data, which could be anything, but is hopefully specified. Try using `sf::st_read("random_shape_file.shp") %>% sf::st_tranform(crs = use_crs)` to deal with this.

### Area of interest

Usually this is geographic and/or taxonomic area of interest. An example area overlapping flor_all is provided in `aoi`. Converting `flor_all` to `sf` allows plotting them together.

```{r aoi}

  flor_all_sf <- flor_all %>%
    sf::st_as_sf(coords = c("long", "lat")
                 , crs = 4326
                 )

  tm_shape(aoi
           , bbox = st_bbox(flor_all_sf)
           ) +
    tm_polygons() +
  tm_shape(flor_all_sf) +
    tm_dots()

```

Filtering `flor_all` to `aoi` is done with `filter_aoi`.

```{r flor_all_aoi}

  flor_aoi <- filter_aoi(flor_all
                         , aoi
                         , crs_aoi = st_crs(aoi)
                         )

  flor_aoi

```

Check that spatial filter worked.

```{r flor_aoi}

  flor_aoi_sf <- flor_aoi %>%
    sf::st_as_sf(coords = c("long", "lat")
                 , crs = 4326
                 )

  tm_shape(aoi
           , bbox = st_bbox(flor_all_sf)
           ) +
    tm_polygons() +
  tm_shape(flor_aoi_sf) +
    tm_dots()

```

## Set scales of interest

There are two scales of particular interest: space (location) and time. Together these are used to set the `context` in further filtering and analysis.

The original location columns probably suggest metre accuracy, or even sub-metre. There may also be a field dampening expectations of such accuracy with estimates of precision for the location. In the following workflow, a precision threshold is set and then an accuracy threshold is adopted. All records with worse precision than threshold are removed, and then all records within the accuracy threshold are lumped. The lumping is done via a raster placed over the `aoi`.

The original time scale probably suggests accuracy to day, or perhaps even hour, or sub-hour. Choose a scale of relevance to your question. In the example below month is used. Thus all data recorded within a spatial location within a month are treated as one 'visit'.

### Precision

Records with precision less than threshold are filtered using `filter_spat_rel`. This takes a dataframe (`df`) as its first argument, in this case `flor_aoi`. `dist_col` specifies the column in `df` that contains the precision estimates. `dist` provides the threshold above which to filter. If there are data sources (or any other columns in `df`) that do not include an estimate of spatial precision, but you would like to keep, this can be done with the argument `over_ride`. This takes a named list, where names need to match the columns in `df`. Any levels within the columns provided in `over_ride` will not be filtered, irrespective of the values in `dist_col`.

```{r flor_aoi_rel}

  context <- c("year", "month", "lat", "long", "cell")

  include_data_name <- c("ALIS","BCM","NVB","TERN")

  flor_rel <- filter_spat_rel(flor_aoi
                              , dist_col = "rel_dist"
                              , dist = 100
                              , context = context
                              , over_ride = list(data_name = include_data_name)
                              )
  
  flor_rel

```

### Rasterize

Now that records with dubious spatial precision have been removed, an accuracy threshold is adpoted by rasterizing remaining records into the cells of `aoi_raster`, created here.

```{r aoi_raster}

  aoi_raster <- raster(ext = round(extent(aoi), -3)
                      , resolution = 30
                      , crs = CRS(paste0("+init=epsg:",use_crs))
                      )

  aoi_raster

```

Rasterizing the current data is then done via `add_raster_cell`. This function has the argument `add_xy` which will add the centroid of the cell back to the data frame using the same names as the original `x` and `y` columns. Alternatively, the `x` and `y` columns will be lost from the returned data frame, replaced with `cell`, the raster cell id.

```{r flor_rel_cell}

  flor_cell <- add_raster_cell(aoi_raster
                               , flor_rel
                               , add_xy = TRUE
                               , crs_df = 4283
                               )

  flor_cell

```










# References

```{r pacCitations, include = FALSE}

  fix_bib(bib_file = "packages.bib")

```
